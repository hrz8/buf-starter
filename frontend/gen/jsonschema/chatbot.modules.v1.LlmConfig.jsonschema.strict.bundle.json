{
  "$defs": {
    "chatbot.modules.v1.LlmConfig.jsonschema.strict.json": {
      "$schema": "https://json-schema.org/draft/2020-12/schema",
      "additionalProperties": false,
      "description": "LlmConfig defines the configuration for the LLM module.\n Controls model selection and inference parameters.",
      "properties": {
        "enabled": {
          "description": "Whether the LLM module is enabled",
          "type": "boolean"
        },
        "maxSteps": {
          "description": "Maximum number of agent loop steps per conversation turn",
          "maximum": 50,
          "minimum": 1,
          "type": "integer"
        },
        "model": {
          "description": "Model identifier (e.g., us.anthropic.claude-sonnet-4-20250514-v1:0)",
          "maxLength": 200,
          "type": "string"
        },
        "provider": {
          "description": "AI provider to use: \"bedrock\" (default)\n Future: \"openai\", \"anthropic\", \"google\", etc.",
          "enum": [
            "bedrock",
            ""
          ],
          "type": "string"
        },
        "sdk": {
          "description": "SDK to use for LLM calls: \"ai-sdk\" (default)\n Future: \"langchain\", \"llamaindex\", etc.",
          "enum": [
            "ai-sdk",
            ""
          ],
          "type": "string"
        },
        "temperature": {
          "description": "Temperature for response randomness (0 = deterministic, 2 = very random)",
          "maximum": 2,
          "minimum": 0,
          "type": "number"
        }
      },
      "required": [
        "enabled",
        "sdk",
        "provider",
        "model",
        "temperature",
        "maxSteps"
      ],
      "title": "Llm Config",
      "type": "object"
    }
  },
  "$id": "chatbot.modules.v1.LlmConfig.jsonschema.strict.bundle.json",
  "$ref": "#/$defs/chatbot.modules.v1.LlmConfig.jsonschema.strict.json",
  "$schema": "https://json-schema.org/draft/2020-12/schema"
}
